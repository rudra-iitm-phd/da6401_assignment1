Model Summary
---------------------------------------
hidden0
weights : (784, 784)
bias : (784, 1)
activation : relu
---------------------------------------
output1
weights : (10, 784)
bias : (10, 1)
activation : softmax
---------------------------------------
Total Number of Parameters : 623290
Loss : 2.92      Train accuracy : 27.07      Validation accuracy : 26.7      Test Accuracy : 25.86
---------------------------------------------------------------------------------------------------------
Loss : 0.71      Train accuracy : 66.85      Validation accuracy : 65.4      Test Accuracy : 64.83
---------------------------------------------------------------------------------------------------------
Loss : 0.51      Train accuracy : 72.72      Validation accuracy : 71.13      Test Accuracy : 70.66
---------------------------------------------------------------------------------------------------------
Loss : 0.44      Train accuracy : 75.28      Validation accuracy : 73.43      Test Accuracy : 72.68
---------------------------------------------------------------------------------------------------------
Loss : 0.4      Train accuracy : 77.25      Validation accuracy : 74.67      Test Accuracy : 74.01
---------------------------------------------------------------------------------------------------------
Loss : 0.36      Train accuracy : 77.87      Validation accuracy : 75.33      Test Accuracy : 74.26
---------------------------------------------------------------------------------------------------------
Loss : 0.33      Train accuracy : 79.72      Validation accuracy : 76.79      Test Accuracy : 75.64
---------------------------------------------------------------------------------------------------------
Loss : 0.31      Train accuracy : 80.52      Validation accuracy : 77.45      Test Accuracy : 76.34
---------------------------------------------------------------------------------------------------------
Loss : 0.29      Train accuracy : 81.05      Validation accuracy : 77.6      Test Accuracy : 76.73
---------------------------------------------------------------------------------------------------------
Loss : 0.28      Train accuracy : 81.1      Validation accuracy : 77.9      Test Accuracy : 76.75
---------------------------------------------------------------------------------------------------------
Loss : 0.28      Train accuracy : 80.93      Validation accuracy : 77.36      Test Accuracy : 76.09
---------------------------------------------------------------------------------------------------------
Loss : 0.26      Train accuracy : 82.58      Validation accuracy : 78.65      Test Accuracy : 77.57
---------------------------------------------------------------------------------------------------------
Loss : 0.25      Train accuracy : 82.98      Validation accuracy : 78.79      Test Accuracy : 77.52
---------------------------------------------------------------------------------------------------------
Loss : 0.24      Train accuracy : 83.32      Validation accuracy : 78.88      Test Accuracy : 77.95
---------------------------------------------------------------------------------------------------------
Loss : 0.24      Train accuracy : 83.15      Validation accuracy : 78.71      Test Accuracy : 77.52
---------------------------------------------------------------------------------------------------------
Traceback (most recent call last):
  File "train.py", line 44, in train
    trainer.learn(nn=nn, optim=optim, loss_fn=loss_fn, lr=configuration_script['learning_rate'], batch_size=configuration_script['batch_size'], epochs = configuration_script['epochs'], acc_metrics=accuracy, loss = loss_fn, beta = configuration_script['beta'], forward=nn.forward, beta1 = configuration_script['beta1'], beta2 = configuration_script['beta2'], weight_decay = configuration_script['weight_decay'], eps = configuration_script['epsilon'])
  File "/Users/rudra_sarkar/Documents/PhD IIT Madras/Intro to Deep Learning M Khapra DA6401/DA6401 Assignment/da6401_assignment1/trainer.py", line 53, in learn
    grads = loss.backpropagate(params)
  File "/Users/rudra_sarkar/Documents/PhD IIT Madras/Intro to Deep Learning M Khapra DA6401/DA6401 Assignment/da6401_assignment1/loss_functions.py", line 85, in backpropagate
    grads[block][layer] = np.dot(grads[block]['a'], params['hidden0']['x'].T)*(1/self.pred_logits.shape[-1])
  File "<__array_function__ internals>", line 180, in dot
KeyboardInterrupt

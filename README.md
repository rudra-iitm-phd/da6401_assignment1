# ğŸ¤– Neural Network for Fashion MNIST and MNIST Image Classification (From Scratch)

This project is part of the **DA6401 Deep Learning** course taught by **Prof. Mitesh Khapra** at **IIT Madras**. The goal is to build a neural network using Python, relying only on the following libraries: 
- `numpy`
- `pandas`
- `matplotlib`

## ğŸ“„ Project Overview

This repository implements a neural network for classifying images from the **MNIST** and **Fashion MNIST** datasets. Below is a brief description of the project files:

| ğŸ“ **File Name**          | ğŸ” **Description**                                                  |
|--------------------------|--------------------------------------------------------------------|
| `activation.py`           | âš¡ Contains the code for activation functions.                      |
| `argument_parser.py`      | ğŸ¯ Code for parsing user-provided arguments.                       |
| `configure.py`            | âš™ï¸ Configures the neural network, loss function, and optimizer.    |
| `data_loader.py`          | ğŸ“¥ Loads data from MNIST or Fashion MNIST based on user choice.    |
| `loss_functions.py`       | ğŸ’€ Implements loss functions and backpropagation.                   |
| `neural_network.py`       | ğŸ§  Defines the neural network architecture and inference logic.    |
| `normalisation.py`        | ğŸ§´ Contains basic data normalization processes.                    |
| `optimizer.py`            | ğŸ› ï¸ Implements various optimizers (SGD, Momentum, NAG, RMSProp, Adam). |
| `preprocess.py`           | ğŸ”„ Contains basic data preprocessing steps.                        |
| `score_metrics.py`        | ğŸ“Š Computes accuracy and other performance metrics.                |
| `shared.py`               | ğŸ”— Shared variables, methods, and objects used across multiple files. |
| `sweep_configuration.py`  | ğŸ§¹ Configuration for Weights & Biases sweep.                       |
| `train.py`                | ğŸš€ High-level code for training the neural network.               |
| `trainer.py`              | ğŸ¤– Integrates components to manage training and logging to Weights & Biases. |
| `weight_init.py`          | ğŸ‹ï¸â€â™‚ï¸ Implements weight initialization techniques (Random, Xavier). |


## âš™ï¸ Getting Started

Follow the steps below to run the project locally.

### ğŸ› ï¸ Prerequisites

Ensure you have Python 3.8.16 or higher installed along with the following packages:
- `numpy`
- `pandas`
- `matplotlib`

### ğŸš€ Clone the Repository

Clone the project to your local machine by running the following command:

```bash
git clone https://github.com/rudra-iitm-phd/da6401_assignment1.git
```
### ğŸ–¥ï¸ Run the Model
Navigate to the directory where the repository was cloned. To run the model with default settings, execute:
Following are the list of arguments which are compatible

```bash
python train.py
```
### ğŸ”§ Customize the Model
To customize parameters like hidden layers, activation functions, etc., run with the arguemnts with the respective values provided by a space
for eg :
```bash
python train.py -b 1024 -o adam -w_d 1e-2 -e 500 -beta1 0.9 -beta2 0.9999  -w_i xavier -lr 1e-2 -a tanh
```
Following is a screen shot provided post running this command

<img width="1440" alt="Screenshot 2025-03-17 at 11 07 34â€¯PM" src="https://github.com/user-attachments/assets/317ed21a-daa7-4303-b008-f0fb1e180858" />



If you need to check out the list of the parameters available run:

``` bash
python train.py -h
```
### ğŸŒŸ List of Arguments 

| ğŸ”§ **Name**              | ğŸ”„ **Default Value**   | ğŸ“œ **Description**                                                       |
|--------------------------|------------------------|-------------------------------------------------------------------------|
| `-wp`, `--wandb_project`    | `myprojectname`        | ğŸ§‘â€ğŸ’» Project name for tracking experiments in the Weights & Biases dashboard. |
| `-we`, `--wandb_entity`     | `myname`               | ğŸ§‘â€ğŸ’» Weights & Biases entity for tracking experiments.                 |
| `-d`, `--dataset`           | `fashion_mnist`        | ğŸ“Š Choices: `["mnist", "fashion_mnist"]`                                |
| `-e`, `--epochs`            | `500`                    | â³ Number of epochs to train the neural network.                        |
| `-b`, `--batch_size`        | `1024`                    | ğŸ“¦ Batch size used to train the neural network.                         |
| `-l`, `--loss`              | `cross_entropy`        | ğŸ’€ Choices: `["mean_squared_error", "cross_entropy"]`                   |
| `-o`, `--optimizer`         | `adam`                  | âš™ï¸ Choices: `["sgd", "momentum", "nag", "rmsprop", "adam", "nadam"]`    |
| `-lr`, `--learning_rate`    | `1e-2`                  | ğŸš€ Learning rate used to optimize model parameters.                     |
| `-m`, `--momentum`          | `0.5`                  | ğŸŒ€ Momentum used by momentum and NAG optimizers.                         |
| `-beta`, `--beta`           | `0.5`                  | ğŸ”¢ Beta used by RMSProp optimizer.                                      |
| `-beta1`, `--beta1`         | `0.9`                  | ğŸ”¢ Beta1 used by Adam and Nadam optimizers.                             |
| `-beta2`, `--beta2`         | `0.9999`                  | ğŸ”¢ Beta2 used by Adam and Nadam optimizers.                             |
| `-eps`, `--epsilon`         | `0.000001`             | ğŸ”¢ Epsilon used by optimizers to prevent division by zero.              |
| `-w_d`, `--weight_decay`    | `1e-2`                  | âš–ï¸ Weight decay used by optimizers to regularize the model.             |
| `-w_i`, `--weight_init`     | `xavier`               | ğŸ² Choices: `["random", "Xavier"]`                                     |
| `-nhl`, `--num_layers`      | `1`                    | ğŸ§  Number of hidden layers in the neural network.                       |
| `-sz`, `--hidden_size`      | `784`                    | ğŸ”² Number of neurons in each hidden layer.                              |
| `-a`, `--activation`        | `relu`              | ğŸŒŸ Choices: `["identity", "sigmoid", "tanh", "ReLU"]`                   |
| `--wandb_sweep`   | `false`       | ğŸ§‘â€ğŸ’» To generate a wandb sweep with the sweep configuration |
| `--sweep_id`   | `null`      | ğŸ§‘â€ğŸ’» Run a sweep agent with a specific sweep id |
### ğŸ’¬ Contact
For any questions or issues, feel free to open an issue or contact me via GitHub.
